from typing import List, Dict, Any, Optional
from .tool import Tool
from .llm import LLM


class Agent:
    """
    Represents an AI agent with reasoning, verification, and self-correction.
    """

    def __init__(
        self,
        name: str,
        backstory: str,
        instructions: str,
        tools: Optional[List[Tool]] = None,
        model_name: str = "openai-gpt-4o-mini",
        max_retries: int = 3,
        verbose: bool = False,
    ):
        """
        Initializes an Agent.

        Args:
            name (str): The agent's name.
            backstory (str): A description of the agent's history/personality.
            instructions (str): Core instructions that define its role.
            tools (List[Tool], optional): Tools the agent can use. Defaults to None.
            model_name (str): The LLM model name to use. Defaults to "openai-gpt-4o".
            max_retries (int): Number of retry attempts if a response is invalid. Defaults to 3.
            verbose (bool): Whether to print debug information. Defaults to False.
        """
        self.name = name
        self.backstory = backstory
        self.instructions = instructions
        self.tools = tools or []
        self.model_name = model_name
        self.max_retries = max_retries
        self.verbose = verbose

    def gather_tool_outputs(self, inputs: Dict[str, Any]) -> str:
        """
        Invokes all assigned tools and gathers their outputs as context.

        Args:
            inputs (Dict[str, Any]): Inputs for the tools.

        Returns:
            str: A formatted string of tool outputs.
        """
        tool_context = []
        for tool in self.tools:
            tool_output = tool.run(inputs.get(tool.name, {}))
            tool_context.append(f"Tool: {tool.name}\nOutput: {tool_output}")
        
        tool_output_text = "\n".join(tool_context)
        
        if self.verbose:
            print(f"\n[Agent {self.name} - Tool Outputs]:\n{tool_output_text}\n")

        return tool_output_text

    def verify_response(self, response: str) -> bool:
        """
        Asks the LLM to self-evaluate whether the response is valid.

        Args:
            response (str): The generated response to verify.

        Returns:
            bool: True if valid, False otherwise.
        """
        verification_prompt = f"""
        You are an AI quality control system. Verify if the following response makes sense 
        and is free of errors. Answer ONLY with "VALID" or "INVALID".
        
        Response:
        {response}

        Verification:
        """.strip()

        verification_result = LLM.infer(self.model_name, verification_prompt).strip().upper()
        
        if self.verbose:
            print(f"\n[Agent {self.name} - Verification Result]: {verification_result}\n")

        return verification_result == "VALID"

    def invoke(self, inputs: Dict[str, Any]) -> str:
        """
        Calls the LLM with the agent's instruction, tool outputs, and reasoning.

        Args:
            inputs (Dict[str, Any]): Inputs relevant to the agent's task.

        Returns:
            str: The response generated by the LLM.
        """
        for attempt in range(1, self.max_retries + 1):
            tool_outputs = self.gather_tool_outputs(inputs)
            prompt = f"""
            Agent Name: {self.name}
            Backstory: {self.backstory}

            Instructions: {self.instructions}

            Context from Tools:
            {tool_outputs if tool_outputs else "No tool context available."}

            User Inputs:
            {inputs if inputs else "No user input provided."}

            Response:
            """.strip()

            if self.verbose:
                print(f"\n[Agent {self.name} - Prompt Sent to LLM]:\n{prompt}\n")

            try:
                response = LLM.infer(self.model_name, prompt)
                
                if self.verbose:
                    print(f"\n[Agent {self.name} - LLM Response]:\n{response}\n")

                if self.verify_response(response):
                    return response
                
                print(f"[Retry {attempt}] Response failed verification. Retrying...")

            except Exception as e:
                print(f"[Retry {attempt}] Encountered error: {e}. Retrying...")

        # If all retries fail, return a fallback response
        fallback_response = f"After {self.max_retries} attempts, I couldn't generate a valid response."
        if self.verbose:
            print(f"[Agent {self.name} - Retry Failed]: {fallback_response}")


        return fallback_response